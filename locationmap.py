import pywikibot
import toolforge

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙˆØª
class settings:
    editsumm = "[[ÙˆØ¨:Ø¨ÙˆØª|Ø¨ÙˆØª]]: Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙˆØ­Ø¯Ø© Ù…Ù† Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©."
    debug = "no"  # Ø§Ø¬Ø¹Ù„Ù‡Ø§ "no" Ù„Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙØ¹Ù„ÙŠ

# Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯
query = """
SELECT DISTINCT
  CONCAT('[[:en:Module:', p.page_title, ']]') AS english_link,
  CONCAT('[[ÙˆØ­Ø¯Ø©:', REPLACE(p.page_title, '_', ' '), ']]') AS arabic_suggested,
  p.page_title
FROM enwiki_p.page AS p
LEFT JOIN enwiki_p.langlinks AS ll
  ON ll.ll_from = p.page_id AND ll.ll_lang = 'ar'
LEFT JOIN enwiki_p.page_props AS pp
  ON pp.pp_page = p.page_id AND pp.pp_propname = 'wikibase_item'
WHERE p.page_namespace = 828
  AND p.page_title LIKE 'Location_map%'
  AND p.page_title NOT LIKE '%/doc%'
  AND p.page_title NOT LIKE '%/sandbox%'
  AND ll.ll_from IS NULL
  AND p.page_is_redirect = 0
  AND pp.pp_value IS NOT NULL
LIMIT 100;
"""

# Ø§Ù„Ø§ØªØµØ§Ù„
site_en = pywikibot.Site('en', 'wikipedia')
site_ar = pywikibot.Site('ar', 'wikipedia')
conn = toolforge.connect('enwiki', 'analytics')

with conn.cursor() as cursor:
    cursor.execute(query)
    results = cursor.fetchall()

# Ø§Ù„Ù†ØªØ§Ø¦Ø¬: (english_link, arabic_suggested, title)
titles = [row[2].decode("utf-8") if isinstance(row[2], bytes) else row[2] for row in results]

for title in titles:
    en_page = pywikibot.Page(site_en, f"Module:{title}")
    if not en_page.exists():
        continue

    text = en_page.text
    ar_title = f"ÙˆØ­Ø¯Ø©:{title.replace('_', ' ')}"
    ar_page = pywikibot.Page(site_ar, ar_title)

    if ar_page.exists():
        print(f"âœ… Ø§Ù„ØµÙØ­Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§: {ar_title}")
        continue

    if settings.debug == "no":
        ar_page.text = text
        ar_page.save(settings.editsumm)
        print(f"ğŸ“„ Ø£Ù†Ø´Ø£Øª {ar_title}")
    else:
        print(f"== Preview Ø¥Ù†Ø´Ø§Ø¡ {ar_title} ==\n{text[:1000]}...\n")
